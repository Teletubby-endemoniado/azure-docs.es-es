### YamlMime:FAQ
metadata:
  title: Preguntas más frecuentes sobre el servicio Speech to Text
  titleSuffix: Azure Cognitive Services
  description: Obtenga respuestas a las preguntas más frecuentes sobre el servicio Speech to Text.
  services: cognitive-services
  author: PanosPeriorellis
  manager: nitinme
  ms.service: cognitive-services
  ms.subservice: speech-service
  ms.topic: conceptual
  ms.date: 02/01/2021
  ms.author: panosper
  ms.openlocfilehash: 2e402d8132f8b94d1bf809a1be42639ee71350d8
  ms.sourcegitcommit: 2cc9695ae394adae60161bc0e6e0e166440a0730
  ms.translationtype: HT
  ms.contentlocale: es-ES
  ms.lasthandoff: 11/03/2021
  ms.locfileid: "131505201"
title: Preguntas más frecuentes sobre el servicio Speech to Text
summary: >
  Si no encuentra respuestas a sus preguntas en estas P+F, [consulte otras opciones de soporte técnico](../cognitive-services-support-options.md?context=%2fazure%2fcognitive-services%2fspeech-service%2fcontext%2fcontext%253fcontext%253d%2fazure%2fcognitive-services%2fspeech-service%2fcontext%2fcontext).
sections:
- name: General
  questions:
  - question: >
      ¿Qué diferencia hay entre un modelo de línea base y un modelo personalizado de conversión de voz en texto?
    answer: >
      Un modelo de línea base se ha entrenado con datos propiedad de Microsoft y ya está implementado en la nube. Puede usar un modelo personalizado con el fin de adaptar un modelo para que se ajuste mejor a un entorno concreto que tenga ruido ambiental o lenguaje específicos. Fábricas, coches o calles ruidosas requerirán un modelo acústico adaptado. Temas como la biología, la física, la radiología, los nombres de productos y los acrónimos personalizados requerirán un modelo de lenguaje adaptado. Si entrena un modelo personalizado, debe comenzar con texto relacionado para mejorar el reconocimiento de términos y frases especiales.
  - question: >
      ¿Por dónde empiezo si quiero usar un modelo de línea base?
    answer: >
      Primero, obtenga una [clave suscripción](overview.md#try-the-speech-service-for-free). Si quiere realizar llamadas REST a los modelos de línea de base implementados previamente, vea las [API REST](./overview.md#reference-docs). Si quiere usar WebSockets, [descargue el SDK](speech-sdk.md).
  - question: >
      ¿Siempre es necesario crear un modelo de voz personalizado?
    answer: >
      No. Si en la aplicación se usa un lenguaje cotidiano genérico, no es necesario personalizar un modelo. Si la aplicación se usa en un entorno con poco o ningún ruido de fondo, tampoco es necesario personalizar un modelo.


      Puede implementar modelos de línea de base y personalizados en el portal, y después ejecutar pruebas de precisión en ellos. Puede usar esta característica para medir la precisión de un modelo de línea de base con respecto a uno personalizado.
  - question: >
      ¿Cómo sabré que el procesamiento del conjunto de datos o modelo se ha completado?
    answer: >
      Actualmente, el estado del modelo o del conjunto de datos en la tabla es la única manera de saberlo. Cuando se complete el procesamiento, el estado será **Succeeded** (Correcto).
  - question: >
      ¿Puedo crear más de un modelo?
    answer: >
      No hay límite en cuanto al número de modelos que puede tener en la colección.
  - question: >
      Me he dado cuenta de que me he equivocado. ¿Cómo cancelo la importación de datos o la creación del modelo que está en curso?
    answer: >
      Actualmente no se puede revertir un proceso de adaptación acústica o de lenguaje. Puede eliminar los modelos y los datos importados cuando estén en un estado terminal.
  - question: >
      Obtengo varios resultados para cada frase con el formato de salida detallado. ¿Cuál debo usar?
    answer: >
      Tome siempre el primer resultado, incluso si otro resultado (de los "N mejores") puede tener un valor de confianza mayor. El servicio de Voz considera que el primer resultado es el mejor. También puede ser una cadena vacía si no se reconoció ninguna voz.


      Los demás resultados probablemente sean peores y puede que no tengan aplicado el uso completo de mayúsculas y los signos de puntuación. Estos resultados son principalmente útiles en escenarios especiales, como ofrecer a los usuarios la opción de elegir correcciones de una lista o tratar con comandos reconocidos incorrectamente.
  - question: >
      ¿Por qué hay diferentes modelos base?
    answer: >
      Puede elegir entre varios modelos base en el servicio de Voz. Cada nombre de modelo contiene la fecha en que se agregó. Cuando empiece a entrenar un modelo personalizado, use el modelo más reciente para obtener la mejor precisión. Cuando un nuevo modelo está disponible, los modelos base más antiguos siguen estando disponibles durante algún tiempo. Puede seguir usando el modelo con el que ha trabajado hasta que se retire (consulte [Ciclo de vida del modelo y el punto de conexión](./how-to-custom-speech-model-and-endpoint-lifecycle.md)). Aun así, se recomienda cambiar al modelo base más reciente para mejorar la precisión.
  - question: >
      ¿Puedo actualizar el modelo existente (apilamiento del modelo)?
    answer: >
      Un modelo existente no se puede actualizar. Como solución alternativa, puede combinar el conjunto de datos anterior con el nuevo y readaptarlo.


      El conjunto de datos antiguo y el nuevo se deben combinar en un único archivo ZIP (para datos acústicos) o en un archivo .txt (para datos de lenguaje). Cuando termine la adaptación, se debe volver a implementar el nuevo modelo actualizado para obtener un punto de conexión nuevo.
  - question: >
      Cuando hay una versión nueva de un modelo base, ¿la implementación se actualiza de forma automática?
    answer: >
      Las implementaciones NO se actualizan de forma automática.


      Si ha adaptado e implementado un modelo, esa implementación permanecerá como está. El modelo implementado se puede retirar, volverse a adaptar con la versión más reciente del modelo base e implementarse de nuevo para mejorar la precisión.


      Los modelos base y los modelos personalizados se retirarán después de un tiempo (consulte [Ciclo de vida del modelo y el punto de conexión](./how-to-custom-speech-model-and-endpoint-lifecycle.md)).
  - question: >
      ¿Puedo descargar mi modelo y ejecutarlo localmente?
    answer: >
      Puede ejecutar un modelo personalizado localmente en un [contenedor de Docker](speech-container-howto.md?tabs=cstt).
  - question: >
      ¿Puedo copiar o trasladar mis conjuntos de datos, modelos e implementaciones a otra región o suscripción?
    answer: >
      Puede usar la [API REST](https://centralus.dev.cognitive.microsoft.com/docs/services/speech-to-text-api-v3-0/operations/CopyModelToSubscription) para copiar un modelo personalizado en otra región o suscripción. Los conjuntos de datos o las implementaciones no se pueden copiar. Puede importar de nuevo un conjunto de datos de otra suscripción y crear ahí puntos de conexión mediante las copias del modelo.
  - question: >
      ¿Se registran mis solicitudes?
    answer: >
      De forma predeterminada, las solicitudes no se registran (ni audio ni transcripción). Si es necesario, puede seleccionar la opción *Log content from this endpoint* (Registrar contenido desde este punto de conexión) al [crear un punto de conexión personalizado](how-to-custom-speech-train-model.md#deploy-a-custom-model). También puede habilitar el registro de audio en el [SDK de voz](how-to-use-logging.md) por solicitud sin crear un punto de conexión personalizado. En ambos casos, los resultados de audio y reconocimiento de las solicitudes se guardarán en un almacenamiento seguro. En el caso de las suscripciones que usan almacenamiento propiedad de Microsoft, estarán disponibles durante 30 días.


      Puede exportar los archivos registrados en la página de implementación de Speech Studio si usa un punto de conexión personalizado con la opción *Log content from this endpoint* (Registrar contenido desde este punto de conexión) habilitada. Si el registro de audio se habilita a través del SDK, llame a la [API](https://centralus.dev.cognitive.microsoft.com/docs/services/speech-to-text-api-v3-0/operations/GetBaseModelLogs) para acceder a los archivos.
  - question: >
      ¿Están limitadas mis solicitudes?
    answer: >
      Consulte [Cuotas y límites de los servicios de Voz](speech-services-quotas-and-limits.md).
  - question: >
      ¿Cómo se cobra el audio de canal doble?
    answer: >
      Si envía cada canal por separado (cada uno en un archivo propio), se le cobrará por la duración de cada archivo. Si envía un solo archivo con cada canal multiplexado juntos, se le cobrará por la duración del archivo individual. Para más información sobre los precios, vea la [página de precios de Azure Cognitive Services](https://azure.microsoft.com/pricing/details/cognitive-services/speech-services/).


      > [!IMPORTANT]

      > Si tiene más dudas sobre la privacidad que le impidan usar el servicio Habla personalizada, póngase en contacto con uno de los canales de soporte técnico.


      ## <a name="increasing-concurrency"></a>Aumento de la simultaneidad


      Consulte [Cuotas y límites de los servicios de Voz](speech-services-quotas-and-limits.md).
- name: Importar datos
  questions:
  - question: >
      ¿Cuál es el límite de tamaño de un conjunto de datos, y por qué existe?
    answer: >
      El límite se debe a la restricción del tamaño de un archivo para la carga HTTP. Consulte [Cuotas y límites de los servicios de Voz](speech-services-quotas-and-limits.md) para conocer el límite real. Puede dividir los datos en varios conjuntos de datos y seleccionar todos ellos para entrenar el modelo.
  - question: >
      ¿Puedo comprimir mis archivos de texto para cargar un archivo de texto mayor?
    answer: >
      No. Actualmente solo se permiten los archivos de texto no comprimidos.
  - question: >
      El informe de datos indica que ha habido expresiones erróneas. ¿Cuál es el problema?
    answer: >
      No es un problema que no se pueda cargar el 100 % de las expresiones de un archivo. Si la gran mayoría de las expresiones de un conjunto de datos acústicos o de lenguaje (por ejemplo, más del 95 %) se importan correctamente, el conjunto de datos se podrá usar. Pero se recomienda comprender la causa del error de las expresiones y corregir los problemas. Los problemas más comunes, como los errores de formato, son fáciles de corregir.
- name: Creación de un modelo acústico
  questions:
  - question: >
      ¿Cuántos datos acústicos necesito?
    answer: >
      Se recomienda empezar con 30 minutos a una hora de datos acústicos.
  - question: >
      ¿Qué datos debo recopilar?
    answer: >
      Recopile datos lo más cercanos posibles al escenario de aplicación y caso de uso. La colección de datos debe coincidir con la aplicación y los usuarios de destino en términos de dispositivo o dispositivos, entornos y tipos de hablante. En general, debe recopilar datos de un intervalo lo más amplio posible de hablantes.
  - question: >
      ¿Cómo debo recopilar los datos acústicos?
    answer: >
      Puede crear una aplicación de recopilación de datos autónoma o usar software de grabación de audio comercial. También puede crear una versión de la aplicación que registre los datos de audio y después los use.
  - question: >
      ¿Debo transcribir los datos de adaptación yo mismo?
    answer: >
      Sí. Puede transcribirlos usted mismo o utilizar un servicio de transcripción profesional. Algunos usuarios prefieren usar transcriptores profesionales, mientras que otros usan la colaboración abierta distribuida o realizan las transcripciones ellos mismos.
  - question: >
      ¿Cuánto tiempo se tardará en entrenar un modelo personalizado con datos de audio?
    answer: >
      Entrenar un modelo con datos de audio puede ser un proceso largo. Dependiendo de la cantidad de datos, puede tardar varios días en crear un modelo personalizado. Si no se puede finalizar en una semana, el servicio podría anular la operación de entrenamiento y notificar que el modelo tiene errores.


      Use una de las [regiones](custom-speech-overview.md#set-up-your-azure-account) donde se disponga de hardware dedicado para el entrenamiento. El servicio Voz usará hasta 20 horas de audio para el entrenamiento en estas regiones. En otras regiones, solo usará hasta 8 horas.


      En general, el servicio procesa aproximadamente 10 horas de datos de audio al día en regiones con hardware dedicado. Solo puede procesar aproximadamente 1 hora de datos de audio al día en otras regiones. Puede copiar el modelo totalmente entrenado en otra región mediante la [API REST](https://centralus.dev.cognitive.microsoft.com/docs/services/speech-to-text-api-v3-0/operations/CopyModelToSubscription). El entrenamiento con solo texto es mucho más rápido y normalmente finaliza en cuestión de minutos.


      Algunos modelos base no se pueden personalizar con datos de audio. Para ellos, el servicio solo utilizará el texto de la transcripción para el entrenamiento y omitirá los datos de audio. Así, el entrenamiento se completará mucho más rápido y los resultados serán los mismos que los del entrenamiento solo con texto. Consulte la [compatibilidad con idiomas](language-support.md#speech-to-text) para obtener una lista de los modelos base que admiten el entrenamiento con datos de audio.
- name: Pruebas de precisión
  questions:
  - question: >
      ¿Qué es Word Error Rate (WER) y cómo se calcula?
    answer: >
      WER es la métrica de evaluación para el reconocimiento de voz. WER se cuenta como el número total de errores, lo que incluye las inserciones, eliminaciones y sustituciones, dividido por el número total de palabras en la transcripción de referencia. Para más información, consulte [Evaluación de la precisión de Custom Speech](how-to-custom-speech-evaluate-data.md#evaluate-custom-speech-accuracy).
  - question: >
      ¿Cómo determino si los resultados de una prueba de precisión son correctos?
    answer: >
      Los resultados muestran una comparación entre el modelo de línea base y el personalizado. Debe aspirar a superar el modelo de línea de base para que la personalización sea útil.
  - question: >
      ¿Cómo puedo determinar el valor WER de un modelo base para ver si se produjo una mejora?
    answer: >
      Los resultados de la prueba sin conexión muestran la precisión de línea base del modelo personalizado y la mejora sobre la línea base.
- name: Creación de un modelo de lenguaje
  questions:
  - question: >
      ¿Cuántos datos de texto tengo que cargar?
    answer: >
      Depende de la diferencia que exista entre el vocabulario y las frases que se usan en la aplicación y los modelos de lenguaje iniciales. Para todas las palabras nuevas, es útil proporcionar el máximo de ejemplos posible de utilización de estas palabras. Para las frases comunes que se usan en la aplicación, también es útil incluir frases en los datos de lenguaje, ya que indican al sistema que escuche también estos términos. Es habitual que haya al menos 100, y normalmente varios cientos de expresiones en el conjunto de datos de lenguaje o más. Además, si se espera que algunos tipos de consultas sean más habituales que otros, puede insertar varias copias de las consultas comunes en el conjunto de datos.
  - question: >
      ¿Puedo simplemente cargar una lista de palabras?
    answer: >
      La carga de una lista de palabras las agregará al vocabulario, pero no enseñará al sistema cómo se usan normalmente. Al proporcionar expresiones completas o parciales (oraciones o frases que es probable que digan los usuarios), el modelo de lenguaje puede aprender las palabras nuevas y cómo se usan. El modelo de lenguaje personalizado es bueno no solo para agregar palabras nuevas al sistema, sino también para ajustar la probabilidad de palabras conocidas para la aplicación. Al proporcionar expresiones completas se ayuda al sistema a aprender mejor.
- name: Modelo de inquilino (Habla personalizada con datos de Microsoft 365)
  questions:
  - question: >
      ¿Qué información se incluye en el modelo de inquilino y cómo se crea?
    answer: >
      Un modelo de inquilino se crea con documentos y correos electrónicos de [grupos públicos](https://support.microsoft.com/office/learn-about-microsoft-365-groups-b565caa1-5c40-40ef-9915-60fdb2d97fa2) que puede ver cualquier usuario de la organización.
  - question: >
      ¿Qué experiencias de voz mejora el modelo de inquilino?
    answer: >
      Cuando el modelo de inquilino se habilita, se crea y se publica, se usa para mejorar el reconocimiento de las aplicaciones empresariales compiladas con el servicio de Voz, que también pasan un token de Azure AD de usuario que indica la pertenencia a la empresa.


      Las experiencias de voz integradas en Microsoft 365, como el Dictado y los subtítulos de PowerPoint, no cambian cuando se crea un modelo de inquilino para las aplicaciones del servicio de voz.
additionalContent: "\n## <a name=\"next-steps\"></a>Pasos siguientes\n\n- [Solución de problemas](troubleshooting.md)\n- [Notas de la versión](releasenotes.md)"
